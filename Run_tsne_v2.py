from parametric_tsne import ParametricTSNE
from transform_data import *
import argparse
import pickle
from keras.models import model_from_json
from sklearn.decomposition import PCA

import matplotlib
matplotlib.use('TkAgg')
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from scipy import stats, interpolate

"""
The training dataset has 5 classes, where the 5th class is where it was classified as "intermedidate".
"""


class Cell_tSNE(object):
	"""
	Encapsulates the tsne model functionality.

	Usage examples:
	#start instance of t-SNE
	CP = Cell_tSNE()

	#Load and prepare the training data
	CP.prepare_train_data("/users/czeddy/documents/workingfolder/tsne/All_Combined_training.txt")

	#Train model
	CP.train()

	#Load previous model
	CP.load_model(trained_model_h5_file='/users/czeddy/documents/workingfolder/tsne/all_confocal/3dmodel.h5',trained_model_json_file='/users/czeddy/documents/workingfolder/tsne/all_confocal/3dmodel.json')

	#tSNE transform training data
	CP.transform_train_data()

	#Plot the transformed training data
	CP.plot_tsne_train_data()

	#transform Y27632 data
	X_y, Y_y, frames_y = CP.transform_test_data(dic=Y27632_dict)

	#plot Y27632 data
	CP.plot_test_data(X_y, Y_y, frames_y)
	"""

	def __init__(self):

		# Perform dimensionality reduction during training, or set true if
		#dimensionality reduction was used during training of previous model
		self.dim_reduct = True
		if self.dim_reduct:
			self.dims_keep = 6 #explains 96% of observed variance.

		#apply normalization methods if desired
		self.l1=False
		self.m_norm = False
		self.l2=False

		#Remove outliers from TSNE plot for each group
		self.clean_data=True

		#compute probability density function
		self.compute_pdf = False


	def prepare_train_data(self,train_file):
		"""
		Prepare training data.
		The nice thing about this is that you can change the training data on the fly, if you wish.
		That is, you can reload a different training set.
		"""
		#first, lets load data
		(X_train, Y_train) = import_train_set(train_file_name = train_file)#'Real_Sim_Augmented.txt')#'All_Combined_training.txt')
		#'Real_Sim_Shear_Size_All.txt')
		#'Real_Sim_Augmented.txt')

		X_train, Y_train = Augment_Size(X_train, Y_train, max_copies=0, s=0.2, balance=False, augment_class=None) #doing nothing.

		X_train = Add_Measures(X_train, add_AR=True, add_FF=True,
							add_convexity=True, add_curl_old=True, add_curl=True,
							add_sphericity=True, add_InscribedArea=True, add_BlebRel=True)
		#if you wish to exclude certain measures:
		#Area,MjrAxis,MnrAxis,Ecc,ConA,EqD,Sol,Ext,Per,conPer,FL,InR
		X_train = Exclude_Measures(X_train, ex_Area = False, ex_MjrAxis=False, ex_MnrAxis=False, ex_Ecc=False,
		 						ex_ConA=False, ex_EqD=False, ex_Sol=False, ex_Ext=False,
								ex_Per=False,ex_conPer=False,ex_FL=False,ex_InR=False,
								ex_bleb=False)
		if min(Y_train)>0:
			Y_train = Y_train-min(Y_train)

		X_train = apply_normalization(X_train, max_norm=self.m_norm, l1_norm=self.l1, l2_norm = self.l2)

		(X_train_scaled, scaler) = preprocess_train_data(X_train, d = 1)

		(X_train_scaled, Y_train_scaled) = Trim_Train_Data(X_train_scaled,Y_train,max_length=15000,balance=False)#max_length=2048,balance=True)
		"""
		Notes: Even though max_length should set how large the dataset for training
		should be, the algorithm requires training set length to be divisible by
		256. Therefore, it may be slightly less.
		"""
		if self.dim_reduct:
			print('Performing dimensionality reduction via PCA prior to training...')
			self.pca = PCA(n_components = self.dims_keep)
			X_train_scaled = self.pca.fit_transform(X_train_scaled)

		self.X_train = X_train_scaled
		self.Y_train = Y_train_scaled
		self.scaler = scaler

	def transform_test_data(self,dic,save_pkl_data=False):
		"""
		dic: dictionary with keys
			filepaths:    contains the filepaths to data you wish to embed.
			csvfilenames: contains the csv filenames within filepaths that have
						  geometrical measurements for each cell, generated by
						  Matlab script "Previous_Cell_2D_v2.m"
			txtfilenames: contains the SVM generated txt file classifications
						  generated from SVM_csv.py
			begin_frames: list of numbers for which frames to start from.

		save_pkl_data: boolean, specify if you wish to save transformed data.

		returns t-SNE embedded data.
		"""

		for i,fpath in enumerate(dic['filepaths']):
			csvfilename=dic['csvfilenames'][i]
			txtfilename=dic['txtfilenames'][i]
			(X, y, frames) = open_and_save_test_data(fpath,csvfilename,txtfilename, 0.53763672)
			X = Add_Measures(X, add_AR=True, add_FF=True,
							 add_convexity=True, add_curl_old=True, add_curl=True,
							 add_sphericity=True, add_InscribedArea=True, add_BlebRel=True)
			#if you wish to exclude certain measures:
			#Area,MjrAxis,MnrAxis,Ecc,ConA,EqD,Sol,Ext,Per,conPer,FL,InR
			X = Exclude_Measures(X, ex_Area = False, ex_MjrAxis=False, ex_MnrAxis=False, ex_Ecc=False,
			 					 ex_ConA=False, ex_EqD=False, ex_Sol=False, ex_Ext=False,
								 ex_Per=False,ex_conPer=False,ex_FL=False,ex_InR=False,
								 ex_bleb=False)

			X = apply_normalization(X, max_norm=self.m_norm, l1_norm=self.l1, l2_norm = self.l2)
			X = preprocess_test_data(X, self.scaler, d = 1)
			if self.dim_reduct:
				X = self.pca.transform(X)

			X = self.transformer.transform(X)

			X = X[dic['begin_frames'][i]:,:]
			y = y[dic['begin_frames'][i]:]

			if i>0:
				frames[:,1]=frames[:,1]+np.max(frames_all[:,1])
				frames_all = np.concatenate((frames_all,frames))
				y_all = np.concatenate((y_all,y))
				X_all = np.concatenate((X_all,X))
			else:
				frames_all = frames
				X_all = X
				y_all = y

		if save_pkl_data:
			with open('embedded_test_data.pkl','wb') as f:
				pickle.dump([X_all, y_all, frames_all], f)

		return X_all, y_all, frames_all



	def train(self, n_components=3, n_iter=300, perplexity=40):
		"""
		Train model by fitting training data from prepare_train_data
		Must run prepare_train_data BEFORE training.
		"""
		transformer = ParametricTSNE(n_components=n_components, n_iter=n_iter, perplexity=perplexity)#sum(Y_train==1)/3)#100)#sum(Y_train==1)/2)
		X_train_tsne = transformer.fit_transform(self.X_train)
		self.X_train_tsne = X_train_tsne
		self.transformer = transformer

	def transform_train_data(self):
		"""
		If you loaded the model, you can load data and then transform it.
		"""
		self.X_train_tsne = self.transformer.transform(self.X_train)
		if self.clean_data:
			self.X_train_clean, self.Y_train_clean = Remove_Outliers(self.X_train_tsne,self.Y_train)

	def save_pkl_train_data(self):
		"""
		Use if you wish to save embedded data as pickle file for some other further purpose.
		"""
		with open('embedded_train_data.pkl','wb') as f:
			pickle.dump([self.X_train_tsne, self.Y_train_scaled], f)

	def load_pkl_train_data(self, train_pkl_file):
		"""
		Use to load previously saved training data after fitting t-SNE
		"""
		with open(train_pkl_file,'rb') as f:
			[X_train_tsne, Y_train] = pickle.load(f)

		self.X_train_tsne = X_train_tsne
		self.Y_train = Y_train

	def save_model(self):
		"""
		Saves JSON and H5 Weights files so you can reload later.
		"""
		model_json = self.transformer.model.to_json()
		with open("3dmodel.json", "w") as json_file:
			json_file.write(model_json)
			# serialize weights to HDF5
		self.transformer.model.save_weights("3dmodel.h5")
		print("Saved model to disk")

	def load_model(self, trained_model_h5_file, trained_model_json_file):
		self.transformer = ParametricTSNE(n_components=3, n_iter=200)
		# json_file = open('2dmodel.json', 'r')
		# loaded_model_json = json_file.read()
		# json_file.close()
		# transformer.model = model_from_json(loaded_model_json)
		# # load weights into new model
		# transformer.model.load_weights("2dmodel.h5")
		print("Loaded model from disk")
		json_file = open(trained_model_json_file,'r')#'./All_Confocal/3dmodel.json', 'r')
		loaded_model_json = json_file.read()
		json_file.close()
		self.transformer.model = model_from_json(loaded_model_json)
		# load weights into new model
		self.transformer.model.load_weights(trained_model_h5_file)#"./All_Confocal/3dmodel.h5")
		print("Loaded model from disk")

	def plot_tsne_train_data(self):
		c = np.array([[1,1,0],
			[1,0,1],
			[0,1,0],
			[0,0,1],
			[0,1,1]])

		labels = ['actin-edge',
				'filopodia',
				'bleb-based',
				'lamellipodia',
				'intermediate']

		fig = plt.figure(1, figsize=(9, 9))
		#plt.clf()
		ax = Axes3D(fig, rect=[0, 0, 1, 1], elev=21, azim=99)
		## for name, label in [('actinedge', 0), ('filopodia', 1), ('bleb-based', 2), \
		## 					('lamellipodia', 3), ('intermediate',4)]:
		# for name, label in [('actinedge', 0), ('filopodia', 1), ('bleb-based', 2), \
		# 					('lamellipodia', 3)]:
		#    ax.text3D(X_train_clean[Y_train_clean == label, 0].mean(),
		# 			 X_train_clean[Y_train_clean==label, 1].mean() + 1.5,
		# 			 X_train_clean[Y_train_clean==label, 2].mean(), name,
		# 			 horizontalalignment='center',
		# 			 bbox=dict(alpha=.5, edgecolor='w', facecolor='w'))

		#y = np.choose(y, [1, 2, 0]).astype(np.float)
		# cs = [0,1,2,3,4]
		if self.clean_data:
			cs = [0,1,2,3]
			for classes in range(len(cs)):
				x = self.X_train_clean[self.Y_train_clean==cs[classes],0]
				y = self.X_train_clean[self.Y_train_clean==cs[classes],1]
				z = self.X_train_clean[self.Y_train_clean==cs[classes],2]
				c_good = c[self.Y_train_clean[self.Y_train_clean==cs[classes]]]
				ax.scatter(x, y, z, c=c_good,
						edgecolor='k',alpha=0.4)

			frame1 = plt.gca()
			frame1.axes.xaxis.set_ticklabels([])
			frame1.axes.yaxis.set_ticklabels([])
			frame1.axes.zaxis.set_ticklabels([])

			plt.show()
		else:
			cs = [0,1,2,3] #exclude intermediate
			for classes in range(len(cs)):
				x = self.X_train_tsne[self.Y_train==cs[classes],0]
				y = self.X_train_tsne[self.Y_train==cs[classes],1]
				z = self.X_train_tsne[self.Y_train==cs[classes],2]
				c_good = c[self.Y_train[self.Y_train==cs[classes]]]
				ax.scatter(x, y, z, c=c_good,
						edgecolor='k',alpha=0.4)

			frame1 = plt.gca()
			frame1.axes.xaxis.set_ticklabels([])
			frame1.axes.yaxis.set_ticklabels([])
			frame1.axes.zaxis.set_ticklabels([])

			plt.show()

	def plot_test_data(self, X, Y, frames):

		c = np.array([[1,1,0],
			[1,0,1],
			[0,1,0],
			[0,0,1],
			[0,1,1]])

		linemarkers=['-','-']#['--','-.']
		scattermarkers=['o','^']
		linecolors=np.array([[1,0,0],[0,0,0]])

		#############################################################################
		#############################EMBED NEW POINTS################################
		m=-1
		for cell_num in list(set(frames[:,1])):
			m=m+1
			####################################################
			################EMBED TRAINING POINTS###############
			####################################################
			fig = plt.figure(1, figsize=(9,9))
			#plt.clf()
			ax = Axes3D(fig, rect=[0, 0, 1, 1], elev=21, azim=99)
			#for name, label in [('actinedge', 0), ('filopodia', 1), ('hemispherebleb', 2), \
			#                    ('lamellipodia', 3), ('smallbleb',4)]:
			#    ax.text3D(X_train_tsne2[Y_train == label, 0].mean(),
			#              X_train_tsne2[Y_train==label, 1].mean() + 1.5,
			#              X_train_tsne2[Y_train==label, 2].mean(), name,
			#              horizontalalignment='center',
			#              bbox=dict(alpha=.5, edgecolor='w', facecolor='w'))

			#y = np.choose(y, [1, 2, 0]).astype(np.float)
			#SHOW TRAINING DATA
			cs = [0,1,2,3] #exclude intermediate

			if self.clean_data:
				cs = [0,1,2,3]
				for classes in range(len(cs)):
					x = self.X_train_clean[self.Y_train_clean==cs[classes],0]
					y = self.X_train_clean[self.Y_train_clean==cs[classes],1]
					z = self.X_train_clean[self.Y_train_clean==cs[classes],2]
					c_good = c[self.Y_train_clean[self.Y_train_clean==cs[classes]]]
					ax.scatter(x, y, z, c=c_good,
							edgecolor='k',alpha=0.1)

				frame1 = plt.gca()
				frame1.axes.xaxis.set_ticklabels([])
				frame1.axes.yaxis.set_ticklabels([])
				frame1.axes.zaxis.set_ticklabels([])

			else:
				cs = [0,1,2,3] #exclude intermediate
				for classes in range(len(cs)):
					x = self.X_train_tsne[self.Y_train==cs[classes],0]
					y = self.X_train_tsne[self.Y_train==cs[classes],1]
					z = self.X_train_tsne[self.Y_train==cs[classes],2]
					c_good = c[self.Y_train[self.Y_train==cs[classes]]]
					ax.scatter(x, y, z, c=c_good,
							edgecolor='k',alpha=0.1)

				frame1 = plt.gca()
				frame1.axes.xaxis.set_ticklabels([])
				frame1.axes.yaxis.set_ticklabels([])
				frame1.axes.zaxis.set_ticklabels([])

			####################################################
			################EMBED NEW POINTS###############
			####################################################
			good_X_data = X[frames[:,1]==cell_num,:]
			good_y_data = Y[frames[:,1]==cell_num]
			c_good = c[Y[frames[:,1]==cell_num]]
			#ax.scatter(good_X_data[0,0],good_X_data[0,1],good_X_data[0,2],c=c_good[0],alpha=1.0)
			# ax.plot(good_X_data[:,0],good_X_data[:,1],good_X_data[:,2],
			# 		linemarkers[m],c=linecolors[m],alpha=1.0)
			ax.plot(good_X_data[:,0],good_X_data[:,1],good_X_data[:,2],
					'-',c='k',alpha=1.0)
			ax.scatter(good_X_data[:,0],good_X_data[:,1],good_X_data[:,2],marker='o'',
						c=c_good[:], edgecolor='k', alpha = 1.0)
			ax.scatter(good_X_data[0,0],good_X_data[0,1],good_X_data[0,2],marker='o'', s=200,
						c=c_good[0].reshape(1,3), edgecolor=np.array([1,1,1]).reshape(1,3), alpha = 1.0)
			ax.scatter(good_X_data[-1,0],good_X_data[-1,1],good_X_data[-1,2],marker='o'', s=200,
						c=c_good[-1].reshape(1,3), edgecolor=np.array([0,0,0]).reshape(1,3), alpha = 1.0)

			plt.show()



Y27632_dict = {
	"filepaths": ['/users/czeddy/documents/workingfolder/drug_treated/BEST_CELLS/Y27632/Cell1/',
				  '/users/czeddy/documents/workingfolder/drug_treated/BEST_CELLS/Y27632/Cell2/',
				  '/users/czeddy/documents/workingfolder/drug_treated/BEST_CELLS/Y27632/Cell3/',
				  '/users/czeddy/documents/workingfolder/drug_treated/BEST_CELLS/Y27632/Cell4/',
				  '/users/czeddy/documents/workingfolder/drug_treated/BEST_CELLS/Y27632/Cell5/'],
	"csvfilenames": ['Cell1',
				     'Cell2',
				     'Cell3',
				     'Cell4',
				     'Cell5'],
	"txtfilenames": ['rbfCell1',
					 'Cell2',
 				     'Cell3',
 				     'Cell4',
 				     'Cell5'],
	"begin_frames":  [0, 0, 0, 0, 0],
}

CN03_dict = {
	"filepaths": ['/users/czeddy/documents/workingfolder/drug_treated/BEST_CELLS/Rho_act/new_060120/Cell8/',
				  '/users/czeddy/documents/workingfolder/drug_treated/BEST_CELLS/Rho_act/new_101519/Cell6/',
				  '/users/czeddy/documents/workingfolder/drug_treated/BEST_CELLS/Rho_act/new_101519/Cell7/',
				  '/users/czeddy/documents/workingfolder/drug_treated/BEST_CELLS/Rho_act/new_060120/Cell9/',
				  '/users/czeddy/documents/workingfolder/drug_treated/BEST_CELLS/Rho_act/new_060120/Cell10/'],
	"csvfilenames": ['Cell8',
				     'Cell6',
				     'Cell7',
				     'Cell9',
				     'Cell10'],
	"txtfilenames": ['Cell8',
					 'Cell6',
 				     'Cell7',
 				     'Cell9',
 				     'Cell10'],
	"begin_frames":  [26, 29, 0, 0, 0],
}
